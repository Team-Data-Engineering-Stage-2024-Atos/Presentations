{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9e920-a46c-471e-8a5b-a3cbe4a20b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import logging\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def create_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        logging.info(f\"Created directory: {directory}\")\n",
    "    else:\n",
    "        logging.info(f\"Directory already exists: {directory}\")\n",
    "\n",
    "def download_file(url, dest_folder, chunk_size=1024*1024, verify_ssl=True):\n",
    "    logging.info(f\"Starting download of {url}\")\n",
    "    try:\n",
    "        create_directory(dest_folder)\n",
    "        local_filename = os.path.join(dest_folder, url.split('/')[-1])\n",
    "        response = requests.get(url, stream=True, verify=verify_ssl)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        t = tqdm(total=total_size, unit='iB', unit_scale=True, desc=local_filename)\n",
    "        \n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "                t.update(len(chunk))\n",
    "                f.write(chunk)\n",
    "        t.close()\n",
    "        \n",
    "        if total_size != 0 and t.n != total_size:\n",
    "            logging.error(f\"Error downloading {local_filename}.\")\n",
    "        else:\n",
    "            logging.info(f\"Downloaded {local_filename}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to download {url}. Error: {e}\")\n",
    "\n",
    "# URLs for various datasets\n",
    "dataset_urls = {\n",
    "    \"owid\": [\n",
    "        \"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/jhu/full_data.csv\"\n",
    "    ],\n",
    "    \"google_cloud\": [\n",
    "        \"https://storage.googleapis.com/covid19-open-data/v2/main.csv\"\n",
    "    ],\n",
    "    \"csse\": [\n",
    "        \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\",\n",
    "        \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\"\n",
    "    ],\n",
    "    \"who\": [\n",
    "        \"https://covid19.who.int/WHO-COVID-19-global-data.csv\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "logging.info(\"Dataset URLs defined.\")\n",
    "\n",
    "# Download datasets from various sources\n",
    "logging.info(\"Starting download of datasets from various sources.\")\n",
    "for source, urls in dataset_urls.items():\n",
    "    for url in urls:\n",
    "        # Disable SSL verification for specific URLs\n",
    "        if \"storage.googleapis.com\" in url:\n",
    "            download_file(url, f\"datasets/{source}\", verify_ssl=False)\n",
    "        else:\n",
    "            download_file(url, f\"datasets/{source}\")\n",
    "logging.info(\"Finished downloading datasets from various sources.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
