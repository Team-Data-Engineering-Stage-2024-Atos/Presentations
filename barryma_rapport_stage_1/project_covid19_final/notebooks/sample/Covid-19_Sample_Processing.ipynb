{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4258a01b-8054-44ac-b871-4b49fbf1fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Sample data for illustration purposes\n",
    "owid_csv = \"\"\"date,location,new_cases,new_deaths,total_cases,total_deaths,reproduction_rate,icu_patients,hosp_patients,weekly_icu_admissions,weekly_hosp_admissions,total_tests,new_tests,total_vaccinations,people_vaccinated,people_fully_vaccinated,total_boosters,new_vaccinations,stringency_index,population,population_density,median_age,aged_65_older,aged_70_older,gdp_per_capita,extreme_poverty,cardiovasc_death_rate,diabetes_prevalence,female_smokers,male_smokers,handwashing_facilities,hospital_beds_per_thousand,life_expectancy,human_development_index\n",
    "2020-01-22,Albania,0.0,0.0,0.0,0.0,,,,,,,,,,,,,2877797.0,104.6,38.2,14.8,4.8,11843.0,,,,,,,,,78.5,0.796\n",
    "2020-01-22,Andorra,0.0,0.0,0.0,0.0,,,,,,,,,,,,,77265.0,,,,,,,,,,,,,,,\n",
    "2020-01-22,Angola,0.0,0.0,0.0,0.0,,,,,,,,,,,,,32866272.0,26.3,16.7,2.5,0.7,6779.0,,,,,,,,,60.8,0.581\n",
    "\"\"\"\n",
    "google_cloud_csv = \"\"\"date,location_key,new_confirmed,new_deceased,new_recovered,new_tested,total_confirmed,total_deceased,total_recovered,total_tested,population,population_density,aged_65_older,gdp_per_capita,smoking_prevalence\n",
    "2020-01-22,AFG,0.0,0.0,,,0.0,0.0,,,,38928341.0,58.0,3.0,1803.0,7.1\n",
    "2020-01-22,AGO,0.0,0.0,,,0.0,0.0,,,,32866272.0,26.0,2.5,6779.0,7.9\n",
    "2020-01-22,ALB,0.0,0.0,,,0.0,0.0,,,,2877797.0,104.0,14.8,11843.0,\n",
    "\"\"\"\n",
    "csse_confirmed_csv = \"\"\"Province/State,Country/Region,Lat,Long,1/22/20\n",
    "NaN,Thailand,15.0000,101.0000,2\n",
    "NaN,Japan,36.0000,138.0000,2\n",
    "\"\"\"\n",
    "csse_deaths_csv = \"\"\"Province/State,Country/Region,Lat,Long,1/22/20\n",
    "NaN,Thailand,15.0000,101.0000,0\n",
    "NaN,Japan,36.0000,138.0000,0\n",
    "\"\"\"\n",
    "who_csv = \"\"\"Date_reported,Country,New_cases,New_deaths,Cumulative_cases,Cumulative_deaths\n",
    "2020-01-22,Thailand,0,0,3,0\n",
    "2020-01-22,Japan,0,0,2,0\n",
    "\"\"\"\n",
    "\n",
    "# Read sample data into DataFrames\n",
    "owid_data = pd.read_csv(StringIO(owid_csv))\n",
    "google_cloud_data = pd.read_csv(StringIO(google_cloud_csv))\n",
    "csse_confirmed = pd.read_csv(StringIO(csse_confirmed_csv))\n",
    "csse_deaths = pd.read_csv(StringIO(csse_deaths_csv))\n",
    "who_data = pd.read_csv(StringIO(who_csv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5893e48d-c153-43d8-b192-6f714865817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean OWID data\n",
    "def clean_owid(data):\n",
    "    data = data.rename(columns={\"date\": \"Date\", \"location\": \"Country\", \"new_cases\": \"NewCases\", \"new_deaths\": \"NewDeaths\"})\n",
    "    data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "    return data\n",
    "\n",
    "# Function to clean Google Cloud data\n",
    "def clean_google_cloud(data):\n",
    "    data = data.rename(columns={\"date\": \"Date\", \"location_key\": \"Country\", \"new_confirmed\": \"NewCases\", \"new_deceased\": \"NewDeaths\"})\n",
    "    data[\"Date\"] = pd.to_datetime(data[\"Date\"], errors='coerce')\n",
    "    data = data.dropna(subset=[\"Date\"])  # Remove rows with invalid dates\n",
    "    return data\n",
    "\n",
    "# Function to clean CSSE Confirmed Cases data\n",
    "def clean_csse_confirmed(data):\n",
    "    data = data.melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"ConfirmedCases\")\n",
    "    data[\"Date\"] = pd.to_datetime(data[\"Date\"], errors='coerce')\n",
    "    data = data.dropna(subset=[\"Date\"])  # Remove rows with invalid dates\n",
    "    return data\n",
    "\n",
    "# Function to clean CSSE Deaths data\n",
    "def clean_csse_deaths(data):\n",
    "    data = data.melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"Deaths\")\n",
    "    data[\"Date\"] = pd.to_datetime(data[\"Date\"], errors='coerce')\n",
    "    data = data.dropna(subset=[\"Date\"])  # Remove rows with invalid dates\n",
    "    return data\n",
    "\n",
    "# Function to clean WHO data\n",
    "def clean_who(data):\n",
    "    data = data.rename(columns={\"Date_reported\": \"Date\", \"Country\": \"Country\", \"New_cases\": \"NewCases\", \"New_deaths\": \"NewDeaths\"})\n",
    "    data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "    return data\n",
    "\n",
    "# Clean datasets\n",
    "owid_data_cleaned = clean_owid(owid_data)\n",
    "google_cloud_data_cleaned = clean_google_cloud(google_cloud_data)\n",
    "csse_confirmed_cleaned = clean_csse_confirmed(csse_confirmed)\n",
    "csse_deaths_cleaned = clean_csse_deaths(csse_deaths)\n",
    "who_data_cleaned = clean_who(who_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cbdc057-0989-4f95-8015-1bd208b8cf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 15:11:24,218 - INFO - Merged Data:\n",
      "2024-08-03 15:11:24,219 - INFO -         Date   Country  NewCases_owid  NewDeaths_owid  total_cases  \\\n",
      "0 2020-01-22   Albania            0.0             0.0          0.0   \n",
      "1 2020-01-22   Andorra            0.0             0.0          0.0   \n",
      "2 2020-01-22    Angola            0.0             0.0          0.0   \n",
      "3 2020-01-22  Thailand            0.0             0.0          0.0   \n",
      "4 2020-01-22     Japan            0.0             0.0          0.0   \n",
      "\n",
      "   total_deaths  reproduction_rate  icu_patients  hosp_patients  \\\n",
      "0           0.0                0.0           0.0            0.0   \n",
      "1           0.0                0.0           0.0            0.0   \n",
      "2           0.0                0.0           0.0            0.0   \n",
      "3           0.0                0.0           0.0            0.0   \n",
      "4           0.0                0.0           0.0            0.0   \n",
      "\n",
      "   weekly_icu_admissions  ...  Province/State   Country   Lat   Long  \\\n",
      "0                    0.0  ...             0.0       NaN   0.0    0.0   \n",
      "1                    0.0  ...             0.0       NaN   0.0    0.0   \n",
      "2                    0.0  ...             0.0       NaN   0.0    0.0   \n",
      "3                    0.0  ...             0.0  Thailand  15.0  101.0   \n",
      "4                    0.0  ...             0.0     Japan  36.0  138.0   \n",
      "\n",
      "   ConfirmedCases  Province/State_csse_deaths  Country/Region_csse_deaths  \\\n",
      "0             0.0                         0.0                         NaN   \n",
      "1             0.0                         0.0                         NaN   \n",
      "2             0.0                         0.0                         NaN   \n",
      "3             2.0                         0.0                    Thailand   \n",
      "4             2.0                         0.0                       Japan   \n",
      "\n",
      "   Lat_csse_deaths  Long_csse_deaths  Deaths  \n",
      "0              0.0               0.0     0.0  \n",
      "1              0.0               0.0     0.0  \n",
      "2              0.0               0.0     0.0  \n",
      "3             15.0             101.0     0.0  \n",
      "4             36.0             138.0     0.0  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge datasets on Country and Date\n",
    "merged_data = pd.merge(owid_data_cleaned, google_cloud_data_cleaned, on=[\"Country\", \"Date\"], suffixes=(\"_owid\", \"_gc\"), how=\"outer\")\n",
    "merged_data = pd.merge(merged_data, who_data_cleaned, on=[\"Country\", \"Date\"], suffixes=(\"\", \"_who\"), how=\"outer\")\n",
    "merged_data = pd.merge(merged_data, csse_confirmed_cleaned, left_on=[\"Country\", \"Date\"], right_on=[\"Country/Region\", \"Date\"], suffixes=(\"\", \"_csse\"), how=\"outer\")\n",
    "merged_data = pd.merge(merged_data, csse_deaths_cleaned, left_on=[\"Country\", \"Date\"], right_on=[\"Country/Region\", \"Date\"], suffixes=(\"\", \"_csse_deaths\"), how=\"outer\")\n",
    "\n",
    "# Rename columns for consistency\n",
    "merged_data = merged_data.rename(columns={\"Country/Region\": \"Country\"})\n",
    "\n",
    "# Fill NaN values with 0 for numerical columns where appropriate\n",
    "for col in merged_data.select_dtypes(include=[np.number]).columns:\n",
    "    merged_data[col] = merged_data[col].fillna(0)\n",
    "\n",
    "# Inspect merged data\n",
    "logging.info(\"Merged Data:\")\n",
    "logging.info(merged_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11bf6543-f120-477b-b359-3c4fb190b726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-03 15:11:25,266 - INFO - Final dataset saved to final_covid19_data_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the final merged dataset\n",
    "final_dataset_path = \"final_covid19_data_sample.csv\"\n",
    "merged_data.to_csv(final_dataset_path, index=False)\n",
    "logging.info(f\"Final dataset saved to {final_dataset_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
