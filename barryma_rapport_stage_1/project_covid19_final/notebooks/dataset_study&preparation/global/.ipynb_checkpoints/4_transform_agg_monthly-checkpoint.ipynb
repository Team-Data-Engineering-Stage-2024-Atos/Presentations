{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50449626-aec7-4ed3-94c9-db9bda1c4035",
   "metadata": {},
   "source": [
    "# TRANSFORMATION - AGGREGATION OF DEATHS BY MONTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13b2118-a853-4026-8e8b-3f25f1a51afa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Scouting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8daf8dc-8a10-420e-a6a2-8a1b8d1f32ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Province_State   Admin2       UID iso2 iso3  code3    FIPS Country_Region  \\\n",
      "0        Alabama  Autauga  84001001   US  USA    840  1001.0             US   \n",
      "1        Alabama  Baldwin  84001003   US  USA    840  1003.0             US   \n",
      "2        Alabama  Barbour  84001005   US  USA    840  1005.0             US   \n",
      "3        Alabama     Bibb  84001007   US  USA    840  1007.0             US   \n",
      "4        Alabama   Blount  84001009   US  USA    840  1009.0             US   \n",
      "\n",
      "         Lat      Long_  ...  2/28/23  3/1/23  3/2/23  3/3/23  3/4/23  3/5/23  \\\n",
      "0  32.539527 -86.644082  ...      230     232     232     232     232     232   \n",
      "1  30.727750 -87.722071  ...      724     726     726     726     726     726   \n",
      "2  31.868263 -85.387129  ...      103     103     103     103     103     103   \n",
      "3  32.996421 -87.125115  ...      109     109     109     109     109     109   \n",
      "4  33.982109 -86.567906  ...      261     261     261     261     261     261   \n",
      "\n",
      "   3/6/23  3/7/23  3/8/23  3/9/23  \n",
      "0     232     232     232     232  \n",
      "1     726     726     727     727  \n",
      "2     103     103     103     103  \n",
      "3     109     109     109     109  \n",
      "4     261     261     261     261  \n",
      "\n",
      "[5 rows x 1154 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DF = pd.read_csv('cleaned_us_deaths_sample.csv')\n",
    "\n",
    "print(DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5ea562ec-6ef6-4ff7-afb9-6d09855dff54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Province_State', 'Admin2', 'UID', 'iso2', 'iso3', 'code3', 'FIPS',\n",
      "       'Country_Region', 'Lat', 'Long_', 'Population'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(DF.columns[:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1bf060-6b3e-4656-be0b-a91237aa87d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f72ef9bb-f42c-4f2f-a48f-ecd98820679e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/30/20</th>\n",
       "      <th>2/23/20</th>\n",
       "      <th>2/10/20</th>\n",
       "      <th>1/23/21</th>\n",
       "      <th>1/30/22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>bar</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1 col2  1/23/20  1/30/20  2/23/20  2/10/20  1/23/21  1/30/22\n",
       "0  foo  bar        1        2        3        4        2        8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'col1': ['foo'],\n",
    "    'col2': ['bar'],\n",
    "    '1/23/20': [1],\n",
    "    '1/30/20': [2],\n",
    "    '2/23/20': [3],\n",
    "    '2/10/20': [4],\n",
    "    '1/23/21': [2],\n",
    "    '1/30/22': [8]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46d6153f-5997-4d71-a9c8-33eea25d8df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1 col2  Total of deaths in January 2020  \\\n",
      "0  foo  bar                                2   \n",
      "\n",
      "   Total of deaths in February 2020  Total of deaths in January 2021  \\\n",
      "0                                 4                                2   \n",
      "\n",
      "   Total of deaths in January 2022  \n",
      "0                                8  \n"
     ]
    }
   ],
   "source": [
    "# Save the non-date columns\n",
    "df_non_date = df[['col1', 'col2']]\n",
    "\n",
    "# Convert the column names to datetime, errors='coerce' will convert unconvertable strings to NaT\n",
    "df.columns = pd.to_datetime(df.columns, errors='coerce', format='%m/%d/%y')\n",
    "\n",
    "# Create a new DataFrame to store the result\n",
    "df_new = df[df.columns[~df.columns.isna()]].copy()\n",
    "\n",
    "# Group by year and month, and take the max value for each group\n",
    "df_new.columns = df_new.columns.to_series().dt.to_period('M')\n",
    "df_new = df_new.groupby(df_new.columns, axis=1).max()\n",
    "\n",
    "# Rename the columns\n",
    "df_new.columns = df_new.columns.strftime('Total of deaths in %B %Y')\n",
    "\n",
    "# Concatenate the non-date columns with the new DataFrame\n",
    "df = pd.concat([df_non_date, df_new], axis=1)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72c3be-dde0-4b3a-b468-18a485ab64a9",
   "metadata": {},
   "source": [
    "## Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4102cedf-343a-4b3a-9244-49123c1a1c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex([       'NaT',        'NaT',        'NaT',        'NaT',\n",
      "                      'NaT',        'NaT',        'NaT',        'NaT',\n",
      "                      'NaT',        'NaT',\n",
      "               ...\n",
      "               '2023-02-28', '2023-03-01', '2023-03-02', '2023-03-03',\n",
      "               '2023-03-04', '2023-03-05', '2023-03-06', '2023-03-07',\n",
      "               '2023-03-08', '2023-03-09'],\n",
      "              dtype='datetime64[ns]', length=1154, freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Save the non-date columns\n",
    "DF_non_date = DF[DF.columns[:11]]\n",
    "\n",
    "# Convert the column names to datetime, errors='coerce' will convert unconvertable strings to NaT\n",
    "DF.columns = pd.to_datetime(DF.columns, errors='coerce', format='%m/%d/%y')\n",
    "\n",
    "print(DF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9d729ac9-a618-4ad1-9fb1-c9064490c13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2020-01-22  2020-01-23  2020-01-24  2020-01-25  2020-01-26  2020-01-27  \\\n",
      "0           0           0           0           0           0           0   \n",
      "1           0           0           0           0           0           0   \n",
      "2           0           0           0           0           0           0   \n",
      "3           0           0           0           0           0           0   \n",
      "4           0           0           0           0           0           0   \n",
      "5           0           0           0           0           0           0   \n",
      "6           0           0           0           0           0           0   \n",
      "7           0           0           0           0           0           0   \n",
      "8           0           0           0           0           0           0   \n",
      "\n",
      "   2020-01-28  2020-01-29  2020-01-30  2020-01-31  ...  2023-02-28  \\\n",
      "0           0           0           0           0  ...         230   \n",
      "1           0           0           0           0  ...         724   \n",
      "2           0           0           0           0  ...         103   \n",
      "3           0           0           0           0  ...         109   \n",
      "4           0           0           0           0  ...         261   \n",
      "5           0           0           0           0  ...          54   \n",
      "6           0           0           0           0  ...         132   \n",
      "7           0           0           0           0  ...         675   \n",
      "8           0           0           0           0  ...         170   \n",
      "\n",
      "   2023-03-01  2023-03-02  2023-03-03  2023-03-04  2023-03-05  2023-03-06  \\\n",
      "0         232         232         232         232         232         232   \n",
      "1         726         726         726         726         726         726   \n",
      "2         103         103         103         103         103         103   \n",
      "3         109         109         109         109         109         109   \n",
      "4         261         261         261         261         261         261   \n",
      "5          54          54          54          54          54          54   \n",
      "6         132         132         132         132         132         132   \n",
      "7         678         678         678         678         678         678   \n",
      "8         172         172         172         172         172         172   \n",
      "\n",
      "   2023-03-07  2023-03-08  2023-03-09  \n",
      "0         232         232         232  \n",
      "1         726         727         727  \n",
      "2         103         103         103  \n",
      "3         109         109         109  \n",
      "4         261         261         261  \n",
      "5          54          54          54  \n",
      "6         132         132         132  \n",
      "7         678         680         680  \n",
      "8         172         172         172  \n",
      "\n",
      "[9 rows x 1143 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame to store the result\n",
    "DF_new = DF[DF.columns[~DF.columns.isna()]].copy()\n",
    "\n",
    "print(DF_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "76f87308-aa37-49e3-b922-5ca3abefd24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2020-01  2020-02  2020-03  2020-04  2020-05  2020-06  2020-07  2020-08  \\\n",
      "0        0        0        0        4        4       11       20       22   \n",
      "1        0        0        1        3        9        9       21       38   \n",
      "2        0        0        0        1        1        1        5        7   \n",
      "3        0        0        0        0        1        1        2        7   \n",
      "4        0        0        0        0        1        1        3       11   \n",
      "5        0        0        0        0        5       10       11       13   \n",
      "6        0        0        0        1       18       27       35       36   \n",
      "7        0        0        0        3        3        5        9       30   \n",
      "8        0        0        4       21       25       28       38       39   \n",
      "\n",
      "   2020-09  2020-10  ...  2022-06  2022-07  2022-08  2022-09  2022-10  \\\n",
      "0       27       31  ...      217      220      222      227      228   \n",
      "1       52       71  ...      683      687      693      712      716   \n",
      "2        7        9  ...       99      100      101      103      103   \n",
      "3       11       15  ...      105      105      105      107      108   \n",
      "4       15       25  ...      246      247      251      258      258   \n",
      "5       15       17  ...       54       54       54       54       54   \n",
      "6       40       41  ...      129      129      129      129      130   \n",
      "7       44       65  ...      633      638      640      656      659   \n",
      "8       42       47  ...      163      165      165      169      169   \n",
      "\n",
      "   2022-11  2022-12  2023-01  2023-02  2023-03  \n",
      "0      230      230      230      230      232  \n",
      "1      716      719      723      724      727  \n",
      "2      103      103      103      103      103  \n",
      "3      108      108      109      109      109  \n",
      "4      259      260      261      261      261  \n",
      "5       54       54       54       54       54  \n",
      "6      130      130      131      132      132  \n",
      "7      661      665      674      675      680  \n",
      "8      169      170      170      170      172  \n",
      "\n",
      "[9 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by year and month, and take the max value for each group\n",
    "DF_new.columns = DF_new.columns.to_series().dt.to_period('M')\n",
    "DF_new = DF_new.groupby(DF_new.columns, axis=1).max()\n",
    "\n",
    "print(DF_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "adf77854-517d-4761-8409-4f5fe0e91ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Total_deaths_01_2020', 'Total_deaths_02_2020', 'Total_deaths_03_2020',\n",
      "       'Total_deaths_04_2020', 'Total_deaths_05_2020', 'Total_deaths_06_2020',\n",
      "       'Total_deaths_07_2020', 'Total_deaths_08_2020', 'Total_deaths_09_2020',\n",
      "       'Total_deaths_10_2020', 'Total_deaths_11_2020', 'Total_deaths_12_2020',\n",
      "       'Total_deaths_01_2021', 'Total_deaths_02_2021', 'Total_deaths_03_2021',\n",
      "       'Total_deaths_04_2021', 'Total_deaths_05_2021', 'Total_deaths_06_2021',\n",
      "       'Total_deaths_07_2021', 'Total_deaths_08_2021', 'Total_deaths_09_2021',\n",
      "       'Total_deaths_10_2021', 'Total_deaths_11_2021', 'Total_deaths_12_2021',\n",
      "       'Total_deaths_01_2022', 'Total_deaths_02_2022', 'Total_deaths_03_2022',\n",
      "       'Total_deaths_04_2022', 'Total_deaths_05_2022', 'Total_deaths_06_2022',\n",
      "       'Total_deaths_07_2022', 'Total_deaths_08_2022', 'Total_deaths_09_2022',\n",
      "       'Total_deaths_10_2022', 'Total_deaths_11_2022', 'Total_deaths_12_2022',\n",
      "       'Total_deaths_01_2023', 'Total_deaths_02_2023', 'Total_deaths_03_2023'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rename the columns\n",
    "DF_new.columns = DF_new.columns.strftime('Total_deaths_%m_%Y')\n",
    "\n",
    "print(DF_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88ae6785-7a6d-4cc1-9aba-f10074005e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Province_State    Admin2       UID iso2 iso3  code3    FIPS Country_Region  \\\n",
      "0        Alabama   Autauga  84001001   US  USA    840  1001.0             US   \n",
      "1        Alabama   Baldwin  84001003   US  USA    840  1003.0             US   \n",
      "2        Alabama   Barbour  84001005   US  USA    840  1005.0             US   \n",
      "3        Alabama      Bibb  84001007   US  USA    840  1007.0             US   \n",
      "4        Alabama    Blount  84001009   US  USA    840  1009.0             US   \n",
      "5        Alabama   Bullock  84001011   US  USA    840  1011.0             US   \n",
      "6        Alabama    Butler  84001013   US  USA    840  1013.0             US   \n",
      "7        Alabama   Calhoun  84001015   US  USA    840  1015.0             US   \n",
      "8        Alabama  Chambers  84001017   US  USA    840  1017.0             US   \n",
      "\n",
      "         Lat      Long_  ...  Total_deaths_06_2022  Total_deaths_07_2022  \\\n",
      "0  32.539527 -86.644082  ...                   217                   220   \n",
      "1  30.727750 -87.722071  ...                   683                   687   \n",
      "2  31.868263 -85.387129  ...                    99                   100   \n",
      "3  32.996421 -87.125115  ...                   105                   105   \n",
      "4  33.982109 -86.567906  ...                   246                   247   \n",
      "5  32.100305 -85.712655  ...                    54                    54   \n",
      "6  31.753001 -86.680575  ...                   129                   129   \n",
      "7  33.774837 -85.826304  ...                   633                   638   \n",
      "8  32.913601 -85.390727  ...                   163                   165   \n",
      "\n",
      "   Total_deaths_08_2022  Total_deaths_09_2022  Total_deaths_10_2022  \\\n",
      "0                   222                   227                   228   \n",
      "1                   693                   712                   716   \n",
      "2                   101                   103                   103   \n",
      "3                   105                   107                   108   \n",
      "4                   251                   258                   258   \n",
      "5                    54                    54                    54   \n",
      "6                   129                   129                   130   \n",
      "7                   640                   656                   659   \n",
      "8                   165                   169                   169   \n",
      "\n",
      "   Total_deaths_11_2022  Total_deaths_12_2022  Total_deaths_01_2023  \\\n",
      "0                   230                   230                   230   \n",
      "1                   716                   719                   723   \n",
      "2                   103                   103                   103   \n",
      "3                   108                   108                   109   \n",
      "4                   259                   260                   261   \n",
      "5                    54                    54                    54   \n",
      "6                   130                   130                   131   \n",
      "7                   661                   665                   674   \n",
      "8                   169                   170                   170   \n",
      "\n",
      "   Total_deaths_02_2023  Total_deaths_03_2023  \n",
      "0                   230                   232  \n",
      "1                   724                   727  \n",
      "2                   103                   103  \n",
      "3                   109                   109  \n",
      "4                   261                   261  \n",
      "5                    54                    54  \n",
      "6                   132                   132  \n",
      "7                   675                   680  \n",
      "8                   170                   172  \n",
      "\n",
      "[9 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the non-date columns with the new DataFrame\n",
    "DF = pd.concat([DF_non_date, DF_new], axis=1)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f53249c5-676a-4948-8e4a-73cd3fc3ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.to_csv('transformed_agg_monthly_us_deaths_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13df2cb-4bee-4c34-affa-e4ea1b748279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
