{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50449626-aec7-4ed3-94c9-db9bda1c4035",
   "metadata": {},
   "source": [
    "# TRANSFORMATION - AGGREGATION OF DEATHS BY YEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13b2118-a853-4026-8e8b-3f25f1a51afa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scouting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8daf8dc-8a10-420e-a6a2-8a1b8d1f32ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Province_State   Admin2       UID iso2 iso3  code3    FIPS Country_Region  \\\n",
      "0        Alabama  Autauga  84001001   US  USA    840  1001.0             US   \n",
      "1        Alabama  Baldwin  84001003   US  USA    840  1003.0             US   \n",
      "2        Alabama  Barbour  84001005   US  USA    840  1005.0             US   \n",
      "3        Alabama     Bibb  84001007   US  USA    840  1007.0             US   \n",
      "4        Alabama   Blount  84001009   US  USA    840  1009.0             US   \n",
      "\n",
      "         Lat      Long_  ...  2/28/23  3/1/23  3/2/23  3/3/23  3/4/23  3/5/23  \\\n",
      "0  32.539527 -86.644082  ...      230     232     232     232     232     232   \n",
      "1  30.727750 -87.722071  ...      724     726     726     726     726     726   \n",
      "2  31.868263 -85.387129  ...      103     103     103     103     103     103   \n",
      "3  32.996421 -87.125115  ...      109     109     109     109     109     109   \n",
      "4  33.982109 -86.567906  ...      261     261     261     261     261     261   \n",
      "\n",
      "   3/6/23  3/7/23  3/8/23  3/9/23  \n",
      "0     232     232     232     232  \n",
      "1     726     726     727     727  \n",
      "2     103     103     103     103  \n",
      "3     109     109     109     109  \n",
      "4     261     261     261     261  \n",
      "\n",
      "[5 rows x 1154 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DF = pd.read_csv('cleaned_us_deaths_sample.csv')\n",
    "\n",
    "print(DF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea562ec-6ef6-4ff7-afb9-6d09855dff54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Province_State', 'Admin2', 'UID', 'iso2', 'iso3', 'code3', 'FIPS',\n",
      "       'Country_Region', 'Lat', 'Long_', 'Population'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(DF.columns[:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1bf060-6b3e-4656-be0b-a91237aa87d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72ef9bb-f42c-4f2f-a48f-ecd98820679e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/30/20</th>\n",
       "      <th>2/23/20</th>\n",
       "      <th>2/10/20</th>\n",
       "      <th>1/23/21</th>\n",
       "      <th>1/30/22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>bar</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1 col2  1/23/20  1/30/20  2/23/20  2/10/20  1/23/21  1/30/22\n",
       "0  foo  bar        1        2        3        4        2        8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'col1': ['foo'],\n",
    "    'col2': ['bar'],\n",
    "    '1/23/20': [1],\n",
    "    '1/30/20': [2],\n",
    "    '2/23/20': [3],\n",
    "    '2/10/20': [4],\n",
    "    '1/23/21': [2],\n",
    "    '1/30/22': [8]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d6153f-5997-4d71-a9c8-33eea25d8df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1 col2  Total of deaths in 2020  Total of deaths in 2021  \\\n",
      "0  foo  bar                        4                        2   \n",
      "\n",
      "   Total of deaths in 2022  \n",
      "0                        8  \n"
     ]
    }
   ],
   "source": [
    "# Save the non-date columns\n",
    "df_non_date = df[['col1', 'col2']]\n",
    "\n",
    "# Convert the column names to datetime, errors='coerce' will convert unconvertable strings to NaT\n",
    "df.columns = pd.to_datetime(df.columns, errors='coerce', format='%m/%d/%y')\n",
    "\n",
    "# Create a new DataFrame to store the result\n",
    "df_new = df[df.columns[~df.columns.isna()]].copy()\n",
    "\n",
    "# Group by year and take the max value for each group\n",
    "df_new.columns = df_new.columns.to_series().dt.to_period('Y')\n",
    "df_new = df_new.groupby(df_new.columns, axis=1).max()\n",
    "\n",
    "# Rename the columns\n",
    "df_new.columns = df_new.columns.strftime('Total of deaths in %Y')\n",
    "\n",
    "# Concatenate the non-date columns with the new DataFrame\n",
    "df = pd.concat([df_non_date, df_new], axis=1)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72c3be-dde0-4b3a-b468-18a485ab64a9",
   "metadata": {},
   "source": [
    "## Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4102cedf-343a-4b3a-9244-49123c1a1c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex([       'NaT',        'NaT',        'NaT',        'NaT',\n",
      "                      'NaT',        'NaT',        'NaT',        'NaT',\n",
      "                      'NaT',        'NaT',\n",
      "               ...\n",
      "               '2023-02-28', '2023-03-01', '2023-03-02', '2023-03-03',\n",
      "               '2023-03-04', '2023-03-05', '2023-03-06', '2023-03-07',\n",
      "               '2023-03-08', '2023-03-09'],\n",
      "              dtype='datetime64[ns]', length=1154, freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Save the non-date columns\n",
    "DF_non_date = DF[DF.columns[:11]]\n",
    "\n",
    "# Convert the column names to datetime, errors='coerce' will convert unconvertable strings to NaT\n",
    "DF.columns = pd.to_datetime(DF.columns, errors='coerce', format='%m/%d/%y')\n",
    "\n",
    "print(DF.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d729ac9-a618-4ad1-9fb1-c9064490c13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2020-01-22  2020-01-23  2020-01-24  2020-01-25  2020-01-26  2020-01-27  \\\n",
      "0           0           0           0           0           0           0   \n",
      "1           0           0           0           0           0           0   \n",
      "2           0           0           0           0           0           0   \n",
      "3           0           0           0           0           0           0   \n",
      "4           0           0           0           0           0           0   \n",
      "5           0           0           0           0           0           0   \n",
      "6           0           0           0           0           0           0   \n",
      "7           0           0           0           0           0           0   \n",
      "8           0           0           0           0           0           0   \n",
      "\n",
      "   2020-01-28  2020-01-29  2020-01-30  2020-01-31  ...  2023-02-28  \\\n",
      "0           0           0           0           0  ...         230   \n",
      "1           0           0           0           0  ...         724   \n",
      "2           0           0           0           0  ...         103   \n",
      "3           0           0           0           0  ...         109   \n",
      "4           0           0           0           0  ...         261   \n",
      "5           0           0           0           0  ...          54   \n",
      "6           0           0           0           0  ...         132   \n",
      "7           0           0           0           0  ...         675   \n",
      "8           0           0           0           0  ...         170   \n",
      "\n",
      "   2023-03-01  2023-03-02  2023-03-03  2023-03-04  2023-03-05  2023-03-06  \\\n",
      "0         232         232         232         232         232         232   \n",
      "1         726         726         726         726         726         726   \n",
      "2         103         103         103         103         103         103   \n",
      "3         109         109         109         109         109         109   \n",
      "4         261         261         261         261         261         261   \n",
      "5          54          54          54          54          54          54   \n",
      "6         132         132         132         132         132         132   \n",
      "7         678         678         678         678         678         678   \n",
      "8         172         172         172         172         172         172   \n",
      "\n",
      "   2023-03-07  2023-03-08  2023-03-09  \n",
      "0         232         232         232  \n",
      "1         726         727         727  \n",
      "2         103         103         103  \n",
      "3         109         109         109  \n",
      "4         261         261         261  \n",
      "5          54          54          54  \n",
      "6         132         132         132  \n",
      "7         678         680         680  \n",
      "8         172         172         172  \n",
      "\n",
      "[9 rows x 1143 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame to store the result\n",
    "DF_new = DF[DF.columns[~DF.columns.isna()]].copy()\n",
    "\n",
    "print(DF_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f87308-aa37-49e3-b922-5ca3abefd24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2020  2021  2022  2023\n",
      "0    48   160   230   232\n",
      "1   161   593   719   727\n",
      "2    32    81   103   103\n",
      "3    46    95   108   109\n",
      "4    63   198   260   261\n",
      "5    22    46    54    54\n",
      "6    45   102   130   132\n",
      "7   156   532   665   680\n",
      "8    63   147   170   172\n"
     ]
    }
   ],
   "source": [
    "# Group by year and take the max value for each group\n",
    "DF_new.columns = DF_new.columns.to_series().dt.to_period('Y')\n",
    "DF_new = DF_new.groupby(DF_new.columns, axis=1).max()\n",
    "\n",
    "print(DF_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf77854-517d-4761-8409-4f5fe0e91ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Total_deaths_2020', 'Total_deaths_2021', 'Total_deaths_2022',\n",
      "       'Total_deaths_2023'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rename the columns\n",
    "DF_new.columns = DF_new.columns.strftime('Total_deaths_%Y')\n",
    "\n",
    "print(DF_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88ae6785-7a6d-4cc1-9aba-f10074005e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Province_State    Admin2       UID iso2 iso3  code3    FIPS Country_Region  \\\n",
      "0        Alabama   Autauga  84001001   US  USA    840  1001.0             US   \n",
      "1        Alabama   Baldwin  84001003   US  USA    840  1003.0             US   \n",
      "2        Alabama   Barbour  84001005   US  USA    840  1005.0             US   \n",
      "3        Alabama      Bibb  84001007   US  USA    840  1007.0             US   \n",
      "4        Alabama    Blount  84001009   US  USA    840  1009.0             US   \n",
      "5        Alabama   Bullock  84001011   US  USA    840  1011.0             US   \n",
      "6        Alabama    Butler  84001013   US  USA    840  1013.0             US   \n",
      "7        Alabama   Calhoun  84001015   US  USA    840  1015.0             US   \n",
      "8        Alabama  Chambers  84001017   US  USA    840  1017.0             US   \n",
      "\n",
      "         Lat      Long_  Population  Total_deaths_2020  Total_deaths_2021  \\\n",
      "0  32.539527 -86.644082       55869                 48                160   \n",
      "1  30.727750 -87.722071      223234                161                593   \n",
      "2  31.868263 -85.387129       24686                 32                 81   \n",
      "3  32.996421 -87.125115       22394                 46                 95   \n",
      "4  33.982109 -86.567906       57826                 63                198   \n",
      "5  32.100305 -85.712655       10101                 22                 46   \n",
      "6  31.753001 -86.680575       19448                 45                102   \n",
      "7  33.774837 -85.826304      113605                156                532   \n",
      "8  32.913601 -85.390727       33254                 63                147   \n",
      "\n",
      "   Total_deaths_2022  Total_deaths_2023  \n",
      "0                230                232  \n",
      "1                719                727  \n",
      "2                103                103  \n",
      "3                108                109  \n",
      "4                260                261  \n",
      "5                 54                 54  \n",
      "6                130                132  \n",
      "7                665                680  \n",
      "8                170                172  \n"
     ]
    }
   ],
   "source": [
    "# Concatenate the non-date columns with the new DataFrame\n",
    "DF = pd.concat([DF_non_date, DF_new], axis=1)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f53249c5-676a-4948-8e4a-73cd3fc3ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.to_csv('transformed_agg_yearly_us_deaths_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfdcef8-6ebe-48bf-aeba-b159868464e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
